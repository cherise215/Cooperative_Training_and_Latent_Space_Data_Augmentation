{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "import torch\n",
    "from medseg.common_utils.basic_operations import load_img_label_from_path,crop_or_pad,rescale_intensity\n",
    "from medseg.models.model_util import makeVariable\n",
    "from medseg.models.advanced_triplet_recon_segmentation_model import AdvancedTripletReconSegmentationModel\n",
    "from medseg.common_utils.vis import plot_image,plot_general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../data/tiny_dataset/ED/001_img.nrrd'\n",
    "label_path = '../data/tiny_dataset/ED/001_seg.nrrd'\n",
    "\n",
    "def load_and_preprocess_image(image_path, label_path,image_size = (192,192)):\n",
    "    image, label, sitkimg,sitklabel = load_img_label_from_path(image_path,label_path)\n",
    "    image,label, _,_,_,_ = crop_or_pad(image=image, label=label,crop_size=image_size)\n",
    "    print(f'load image: {image.shape}, label: {label.shape}')\n",
    "    return image,label,sitkimg,sitklabel\n",
    "\n",
    "image_size = (192,192)\n",
    "image,label,sitkimg,sitklabel = load_and_preprocess_image(image_path,label_path,image_size)\n",
    "slice_id = 5\n",
    "plt.subplot(121)\n",
    "plt.title(f'Image slice {slice_id}')\n",
    "plt.imshow(image[slice_id],cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.title(f'Label slice {slice_id}')\n",
    "plt.imshow(label[slice_id],cmap='gray',interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load saved models (fast thinking network + slow thinking network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we load the model trained w/ standard training\n",
    "checkpoint_dir = '../saved/train_ACDC_10_n_cls_4/ACDC/standard_training_test_no_noise/0/model/best/checkpoints'\n",
    "segmentation_model = AdvancedTripletReconSegmentationModel(network_type = 'FCN_16_standard',\n",
    "                                                          checkpoint_dir=checkpoint_dir,\n",
    "                                                          num_classes=4,use_gpu=True,debug=False)\n",
    "\n",
    "\n",
    "segmentation_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract latent image content code z_i and shape code z_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "imageV = makeVariable(torch.from_numpy(image[:,np.newaxis,:,:]),type='float',requires_grad=False,use_gpu=True)\n",
    "labelV = makeVariable(torch.from_numpy(label),type='long',requires_grad=False,use_gpu=True)\n",
    "imageV = rescale_intensity(imageV)\n",
    "segmentation_model.eval()\n",
    "(z_i,z_s), initial_predict = segmentation_model.fast_predict(imageV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Perform latent code maskings on latent image content code for corrupted image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gen_corrupted_image(segmentation_model, latent_code, reference_image,method='channel', max_threshold=0.5,soft_masking=True,random_threshold=True,eval=False):\n",
    "    assert max_threshold>=0 and max_threshold<=1, f'max_threshold {max_threshold} must be in [0,1]' \n",
    "    if max_threshold>0:\n",
    "        perturbed_z_i_0,mask = segmentation_model.perturb_latent_code(latent_code =latent_code,\n",
    "                                                                    label_y=reference_image,perturb_type=method,\n",
    "                                                                    decoder_function = segmentation_model.model['image_decoder'],\n",
    "                                                                    loss_type= 'mse',\n",
    "                                                                    if_soft=soft_masking,\n",
    "                                                                    threshold=max_threshold,random_threshold=random_threshold)\n",
    "        perturbed_image_0 =segmentation_model.decoder_inference(decoder =segmentation_model.model['image_decoder'],\n",
    "                                                                    latent_code = perturbed_z_i_0,eval=eval,disable_track_bn_stats=True)\n",
    "    else:\n",
    "        perturbed_image_0 =segmentation_model.decoder_inference(decoder =segmentation_model.model['image_decoder'],\n",
    "                                                                latent_code = latent_code,eval=eval,disable_track_bn_stats=True)\n",
    "        mask = torch.ones_like(latent_code,device=latent_code.device, dtype = latent_code.dtype,requires_grad=False)\n",
    "        perturbed_z_i_0 = latent_code\n",
    "    return perturbed_image_0, perturbed_z_i_0,mask\n",
    "\n",
    "## Note: here, we use a fixed threhold each time for ease of comparison\n",
    "thresholds =[0, 0.1,0.2,0.3,0.4,0.5]\n",
    "random_threshold = False\n",
    "methods = ['dropout','channel','spatial'] ## 'channel', 'spatial' are targeted masking methods.\n",
    "soft_masking = True ## for targeted masking.\n",
    "results = {}\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    results[method] ={}\n",
    "    for j,threshold in enumerate(thresholds):\n",
    "        corrupted_img, masked_z, mask = gen_corrupted_image(segmentation_model,latent_code=z_i,reference_image=imageV,\n",
    "                                                method=method,soft_masking=soft_masking,max_threshold=threshold, random_threshold=random_threshold)\n",
    "        results[method][threshold] = [corrupted_img, masked_z, mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualization: Generated challenging examples by different masking schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "fig,axes = plt.subplots(len(methods),1+len(thresholds),figsize=(10,6))\n",
    "font_size = 10\n",
    "slice_id =4\n",
    "for i,method in enumerate(methods):\n",
    "    plot_image(image[slice_id],ax = axes[i,0], title = 'Input',font_size=font_size)\n",
    "    for j,threshold in enumerate(thresholds):\n",
    "        result = results[method][threshold]\n",
    "        subtitle = f'{method}: {threshold*100}%'\n",
    "        plot_image(result[0].detach().cpu().numpy()[slice_id,0],ax = axes[i,j+1], title =subtitle,font_size=font_size)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.04, hspace=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Perform latent code maskings on latent shape code for corrupted segmentation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## corrupted shape\n",
    "from medseg.common_utils.uncertainty import cal_batch_entropy_maps\n",
    "def gen_corrupted_segmentation(segmentation_model, latent_code, reference_segmentation,method='channel', max_threshold=0.5,soft_masking=True,random_threshold=True,eval=False):\n",
    "    assert max_threshold>=0 and max_threshold<=1, f'max_threshold {max_threshold} must be in [0,1]' \n",
    "    if max_threshold>0:\n",
    "        perturbed_z_s_0,mask = segmentation_model.perturb_latent_code(latent_code =latent_code,\n",
    "                                                                    label_y=reference_segmentation,perturb_type=method,\n",
    "                                                                    decoder_function = segmentation_model.model['segmentation_decoder'],\n",
    "                                                                    loss_type= 'ce', \n",
    "                                                                    if_soft=soft_masking,\n",
    "                                                                    threshold=max_threshold,random_threshold=random_threshold,\n",
    "                                                                    ) \n",
    "        perturbed_segmentation_0 =segmentation_model.decoder_inference(decoder =segmentation_model.model['segmentation_decoder'],\n",
    "                                                                    latent_code = perturbed_z_s_0,eval=eval,disable_track_bn_stats=True)\n",
    "    else:\n",
    "        perturbed_segmentation_0 =segmentation_model.decoder_inference(decoder =segmentation_model.model['segmentation_decoder'],\n",
    "                                                                latent_code = latent_code,eval=eval,disable_track_bn_stats=True)\n",
    "        mask = torch.ones_like(latent_code,device=latent_code.device, dtype = latent_code.dtype,requires_grad=False)\n",
    "        perturbed_z_s_0 = latent_code\n",
    "    return perturbed_segmentation_0, perturbed_z_s_0,mask\n",
    "\n",
    "## Note: here, we use a fixed threhold each time for ease of comparison\n",
    "thresholds =[0, 0.1,0.2,0.3,0.4,0.5]\n",
    "methods = ['dropout','channel','spatial'] ## 'channel', 'spatial' are targeted masking methods.\n",
    "soft_masking = True ## for targeted masking.\n",
    "results = {}\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    results[method] ={}\n",
    "    for j,threshold in enumerate(thresholds):\n",
    "        corrupted_seg, masked_z, mask = gen_corrupted_segmentation(segmentation_model,latent_code=z_s,reference_segmentation=labelV,\n",
    "                                                method=method,soft_masking=soft_masking,max_threshold=threshold, random_threshold=random_threshold)\n",
    "        ## soft FTN's prediction.\n",
    "        soft_max_prob = torch.nn.functional.softmax(corrupted_seg/2.0,dim=1)\n",
    "        results[method][threshold] = [corrupted_seg.max(1)[1],soft_max_prob, masked_z, mask]\n",
    "# visualization\n",
    "fig,axes = plt.subplots(len(methods)*2,1+len(thresholds),figsize=(10,10))\n",
    "font_size = 10\n",
    "slice_id =4\n",
    "for i,method in enumerate(methods):\n",
    "    plot_general(label[slice_id],ax =axes[2*i,0], title = 'GT',font_size=font_size,cmap ='gray')\n",
    "    plot_general(label[slice_id]*0,ax =axes[2*i+1,0], title = 'GT',font_size=font_size,cmap ='gray')\n",
    "\n",
    "    for j,threshold in enumerate(thresholds):\n",
    "        result = results[method][threshold]\n",
    "        subtitle = f'{method}: {threshold*100}%'\n",
    "        pred_hard_map =result[0].detach().cpu().numpy()\n",
    "        entropy_map  = cal_batch_entropy_maps(result[1].detach().cpu().numpy())\n",
    "        plot_general(pred_hard_map[slice_id],ax = axes[2*i,j+1], title =subtitle,font_size=font_size)\n",
    "        plot_general(entropy_map[slice_id],ax = axes[2*i+1,j+1], title =subtitle,font_size=font_size,cmap ='jet')\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.04, hspace=0.04)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e074d6499f410d23782286b9d502b4e80004fd124ddaec7c72b32d9745d55c2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('new_benchmark': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
